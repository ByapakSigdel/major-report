\section{Background Theory}
The rapid advancement of human-computer interaction (HCI) technologies has paved the way beyond traditional input devices towards more intuitive interfaces. Among these, Gesture-based systems have emerged as a powerful mode of interaction where users engage with digital systems through physical movements, particularly of the hands. This evolution is particularly significant in applications such as gaming, virtual and augmented reality, assistive technology, and robotics.

The MPU6050, a 6-DoF inertial measurement unit (IMU) combining a 3-axis gyroscope and a 3-axis accelerometer, is widely used for real-time tracking of wrist orientation and movement, crucial for recognizing hand gestures [1], [2]. For detecting finger movements, flex sensors are employed, which vary resistance based on bending, providing analog signals proportional to flexion [3]. Alternatively, mechanical switches, activated by levers attached to finger components, offer a digital input method with tactile feedback. Data from these sensors are processed by microcontrollers like the Arduino Mega, which provides ample I/O support. For seamless interaction with external applications, the ESP8266 Wi-Fi module facilitates wireless data transmission, ensuring low-latency communication between the wearable device and the host system [4].

Device housing commonly utilizes 3D-printed PLA filament, chosen for its lightweight properties, customizability, and suitability for ergonomic wearable enclosures that maintain sensor alignment [5]. In the software domain, gesture data is mapped to real-time responses within a digital environment. Game engines, such as Unreal Engine, support external hardware integration, enabling the visualization of hand movements from a first-person perspective [6]. This establishes a seamless connection between physical actions and virtual reactions, particularly effective in immersive puzzle-based or simulation games. Ultimately, gesture-based input systems enhance user experience by aligning digital control with natural human motion, proving ideal for applications ranging from gaming to assistive technology.

\section{Applications}
The data glove system finds applications in various fields including:
\begin{itemize}
    \item Virtual and Augmented Reality (VAR)
    \item Assistive Technology
    \item Gaming
    \item Robotics Control
    \item Smart Environments / IoT Applications
    \item Educational Tools
\end{itemize}

\section{Scope}
The project encompasses several key areas for development and future expansion:
\begin{itemize}
    \item Integration with machine learning models to improve gesture recognition accuracy
    \item Addition of haptic feedback for more immersive interaction
    \item Expansion to full-body motion capture using additional wearable sensors
    \item Development of a mobile or desktop interface for visualizing and mapping gestures
    \item Incorporating voice + gesture multimodal control systems
\end{itemize}
